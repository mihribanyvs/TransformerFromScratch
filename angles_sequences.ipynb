{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RxLr3K4MCZZa"
      },
      "source": [
        "##Installation of the libraries"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "VKen0_khYLsy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "WOpqGFLLtdTJ"
      },
      "outputs": [],
      "source": [
        "!pip install -q transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dqat9Mqke5_y",
        "outputId": "f1a93cf3-eed7-4d35-ef28-8b0b68635b37"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting biopython\n",
            "  Downloading biopython-1.83-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from biopython) (1.25.2)\n",
            "Installing collected packages: biopython\n",
            "Successfully installed biopython-1.83\n"
          ]
        }
      ],
      "source": [
        "!pip install biopython"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2dcG5B0v7sNw",
        "outputId": "6e86b051-2afa-4688-948e-d9da98d28f74"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m56.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105\n"
          ]
        }
      ],
      "source": [
        "#!pip3 uninstall --yes torch torchaudio torchvision torchtext torchdata\n",
        "!pip3 install torch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LH_JLvuAIbf-"
      },
      "source": [
        "Torch optimization."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ajkx476vCNeg"
      },
      "source": [
        "##All libraries needed for training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "HdSZUMUnOd6t"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import math\n",
        "import numpy as np\n",
        "import random\n",
        "import logging\n",
        "\n",
        "# Bring in PyTorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "# Most of the examples have typing on the signatures for readability\n",
        "from typing import Optional, Callable, List, Tuple\n",
        "from Bio import SeqIO\n",
        "# For data loading\n",
        "from torch.utils.data import Dataset, IterableDataset, TensorDataset, DataLoader\n",
        "import json\n",
        "import glob\n",
        "import gzip\n",
        "import bz2\n",
        "\n",
        "# For progress and timing\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "import shutil\n",
        "from Bio.PDB import PDBList\n",
        "from Bio.PDB.MMCIFParser import MMCIFParser\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "MLizYwG0Iaf_"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmLGfrATCu2f"
      },
      "source": [
        "##Data processing"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from Bio.PDB import PICIO, PDBIO\n",
        "from Bio import PDB\n",
        "from typing import TypedDict, Dict, Tuple\n",
        "\n",
        "def angle_seq(file_path, file_model):\n",
        "  # file_path = \"AF-A0A1D8PD42-F1-model_v4.cif\"\n",
        "  # file_model = \"AF-A0A1D8PD42-F1-model_v4\"\n",
        "  pdbl = PDBList()\n",
        "  pdbl.retrieve_pdb_file(file_path, file_format='mmCif', pdir=\".\")\n",
        "  # import the needed class\n",
        "  # instantiate the class to prepare the parser\n",
        "  cif_parser = MMCIFParser()\n",
        "  #structure = cif_parser.get_structure(\"3goe\", \"3goe.cif\")\n",
        "  structure = cif_parser.get_structure(file_model, file_path)\n",
        "  model0 = structure[0]\n",
        "  chain_A = model0['A']  # and we get chain A\n",
        "  # dictionary converting 3-letter codes to 1-letter codes\n",
        "  # this is a very common need in bioinformatics of proteins\n",
        "  d3to1 = {'CYS': 'C', 'ASP': 'D', 'SER': 'S', 'GLN': 'Q', 'LYS': 'K',\n",
        "  'ILE': 'I', 'PRO': 'P', 'THR': 'T', 'PHE': 'F', 'ASN': 'N',\n",
        "  'GLY': 'G', 'HIS': 'H', 'LEU': 'L', 'ARG': 'R', 'TRP': 'W',\n",
        "  'ALA': 'A', 'VAL':'V', 'GLU': 'E', 'TYR': 'Y', 'MET': 'M'}\n",
        "\n",
        "  sequence = []\n",
        "  for residue in chain_A:\n",
        "      # for simplicity we can use X for heteroatoms (ions and water)\n",
        "      sequence.append(d3to1.get(residue.get_resname(), 'X'))  #converts water and ions to X\n",
        "  seq = ' '.join(sequence)\n",
        "\n",
        "  structure.atom_to_internal_coordinates() # turns xyz coordinates into angles and bond lengths\n",
        "\n",
        "  chain:PDB.Chain.Chain = list(structure.get_chains())[0]#iterator of chains, turns it into list, [0] first chain\n",
        "\n",
        "  ic_chain: PDB.internal_coords.IC_Chain = chain.internal_coord #this access the internal chain coords of the chain object\n",
        "\n",
        "  d: Dict[Tuple[PDB.internal_coords.AtomKey,\n",
        "                PDB.internal_coords.AtomKey,\n",
        "                PDB.internal_coords.AtomKey,\n",
        "                PDB.internal_coords.AtomKey],\n",
        "          PDB.internal_coords.Dihedron] = ic_chain.dihedra\n",
        "\n",
        "  cnt = 1\n",
        "  phi_angles = {}\n",
        "  phi_angles_list = []\n",
        "  psi_angles = {}\n",
        "  psi_angles_list = []\n",
        "\n",
        "  for key in d:\n",
        "      if key[0].akl[3] == 'N' and key[1].akl[3] == 'CA' and key[2].akl[3] == 'C' and key[3].akl[3] == 'N':\n",
        "          phi_angles[key] = d[key].angle\n",
        "          phi_angles_list.append(d[key].angle)\n",
        "      elif key[0].akl[3] == 'CA' and key[1].akl[3] == 'C' and key[2].akl[3] == 'N' and key[3].akl[3] == 'CA':\n",
        "          psi_angles[key] = d[key].angle\n",
        "          psi_angles_list.append(d[key].angle)\n",
        "\n",
        "\n",
        "  structure.internal_to_atom_coordinates(verbose = True)\n",
        "  io = PDBIO() #this is to write a pdb file again\n",
        "  io.set_structure(structure)#set structure, the structure you wan tin the pdb file\n",
        "\n",
        "  phi_angles_list.append(0)\n",
        "  psi_angles_list.append(0)\n",
        "\n",
        "  phi = np.asarray(phi_angles_list,dtype=np.float32)*(np.pi/180)\n",
        "  psi = np.asarray(psi_angles_list,dtype=np.float32)*(np.pi/180)\n",
        "  angles = np.vstack((psi,phi))\n",
        "\n",
        "  # out_seq.write(seq)\n",
        "  # out_angle.write(angles)\n",
        "  return seq , angles\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "1lZ4urGZUhzW"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_files_in_main_folder(main_folder_path):\n",
        "    # List all subfolders in the main folder\n",
        "    subfolders = os.listdir(main_folder_path)\n",
        "\n",
        "    for subfolder in subfolders:\n",
        "        subfolder_name = os.path.basename(subfolder)\n",
        "        file_path = os.path.join(main_folder_path, subfolder_name)\n",
        "\n",
        "        if subfolder_name.endswith('.cif'):\n",
        "            # Extract the base name (excluding \".cif\")\n",
        "            file_model = subfolder_name[:-4]\n",
        "            newpath = os.path.join('/content/source', file_model)\n",
        "            # print('new path', newpath)\n",
        "            if not os.path.exists(newpath):\n",
        "              os.makedirs(newpath)\n",
        "              # with open(f\"{file_model}.txt\" , 'w') as sequence:\n",
        "              #   with open(f\"{file_model}.txt\", 'w') as target_angle:\n",
        "            seq , angles = angle_seq(file_path, file_model)\n",
        "              # print('fl path', file_path)\n",
        "              # sequence = open(f\"{file_model}.csv\" , 'w', )\n",
        "              # target_angle = open(f\"{file_model}.csv\", 'w')\n",
        "              # sequence.write(seq)\n",
        "              # target_angle.write(angles)\n",
        "            seq_path = os.path.join(newpath,f\"seq_{file_model}.csv\" )\n",
        "            ang_path = os.path.join(newpath, f\"angle_{file_model}.csv\")\n",
        "            # print('seq path:', seq_path, '\\n', 'angl path:', ang_path)\n",
        "\n",
        "            torch.save(seq , seq_path)\n",
        "            torch.save(angles, ang_path)\n",
        "\n",
        "    print('finish')"
      ],
      "metadata": {
        "id": "aBNpSby_zkiA"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "process_files_in_main_folder('/content/data')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "APlvQdE1x7CX",
        "outputId": "6362c9d4-e271-485e-89a8-22f89226f1d2"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new path /content/source/AF-Q9SVM3-F1-model_v4\n",
            "Downloading PDB structure '/content/data/af-q9svm3-f1-model_v4.cif'...\n",
            "Desired structure doesn't exist\n",
            "AF-Q9SVM3-F1-model_v4 A coordinates for 0 dihedra updated in 0 iterations\n",
            "new path /content/source/AF-F4I3J6-F1-model_v4\n",
            "Downloading PDB structure '/content/data/af-f4i3j6-f1-model_v4.cif'...\n",
            "Desired structure doesn't exist\n",
            "AF-F4I3J6-F1-model_v4 A coordinates for 0 dihedra updated in 0 iterations\n",
            "new path /content/source/AF-B3H5J3-F1-model_v4\n",
            "Downloading PDB structure '/content/data/af-b3h5j3-f1-model_v4.cif'...\n",
            "Desired structure doesn't exist\n",
            "AF-B3H5J3-F1-model_v4 A coordinates for 0 dihedra updated in 0 iterations\n",
            "new path /content/source/AF-Q84WY5-F1-model_v4\n",
            "Downloading PDB structure '/content/data/af-q84wy5-f1-model_v4.cif'...\n",
            "Desired structure doesn't exist\n",
            "AF-Q84WY5-F1-model_v4 A coordinates for 0 dihedra updated in 0 iterations\n",
            "finish\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "when we want to use the folders and files in the code we want a for loop to go to each folder, then use the angle and sequence folders and use them in our code"
      ],
      "metadata": {
        "id": "QbA_NCPVXj8v"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dkQloUgpig5U"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}