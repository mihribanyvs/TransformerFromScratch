{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BxVc9geyN8Ft"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import math"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Find the distance"
      ],
      "metadata": {
        "id": "ttVXqRHckKZv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# output =[x1, y1]\n",
        "# target = [x2, y2]\n",
        "def distance(output_seq, target_seq):\n",
        "  # this function find the distance between two point on Torus and we can use it as our loss function\n",
        "  [x1, y1] = output_seq\n",
        "  [x2, y2] = target_seq\n",
        "  ax_x = min(abs(x2-x1), math.pi -abs(x2-x1))\n",
        "  ax_y = min(abs(y2-y1), math.pi -abs(y2-y1))\n",
        "  d = np.sqrt(ax_x**2 + ax_y**2 )\n",
        "  return d"
      ],
      "metadata": {
        "id": "J2bITga_N-_m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# in the class mode\n",
        "class TorusDistanceCalculator:\n",
        "    def __init__(self, output_seq, target_seq):\n",
        "        self.output_seq = output_seq\n",
        "        self.target_seq = target_seq\n",
        "\n",
        "    def calculate_distance(self):\n",
        "        [x1, y1] = self.output_seq\n",
        "        [x2, y2] = self.target_seq\n",
        "        ax_x = min(abs(x2-x1), math.pi -abs(x2-x1))\n",
        "        ax_y = min(abs(y2-y1), math.pi -abs(y2-y1))\n",
        "        d = np.sqrt(ax_x**2 + ax_y**2)\n",
        "        return d"
      ],
      "metadata": {
        "id": "B7OaYTOdmS4W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VKwIBejbmaXS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Normalization Function\n"
      ],
      "metadata": {
        "id": "ek6TTRE2kHKj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "y = \\frac{x - \\mathrm{E}[x]}{ \\sqrt{\\mathrm{Var}[x] + ϵ}} * γ + β\n",
        "\n"
      ],
      "metadata": {
        "id": "wRZV8U0Z7sDu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def normalization (output , output_dim, eps =1e-12  ):\n",
        "  ## I used the nn.LayerNorm library guidance\n",
        "  # eps : we can put it any small number, in one code also it was written 1e-8\n",
        "  weight = nn.Parameter(torch.ones(output_dim))\n",
        "  bias = nn.Parameter(torch.zeros(output_dim))\n",
        "\n",
        "  mu = np.mean(output ,axis =-1, keepdims=True)\n",
        "  var = np.std((output-mu)**2 ,axis =-1, keepdims=True)\n",
        "  std = np.sqrt(var + eps)\n",
        "  y = bias + weight* (output -mu)/std\n",
        "  return y"
      ],
      "metadata": {
        "id": "gGQUnCsbmbix"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LayerNormalize(nn.Module):\n",
        "\n",
        "    def __init__(self, hidden_dim: int, eps: float = 1e-12):\n",
        "        super().__init__()\n",
        "        self.weight = nn.Parameter(torch.ones(hidden_dim))\n",
        "        self.bias = nn.Parameter(torch.zeros(hidden_dim))\n",
        "        self.eps = eps\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        mu = x.mean(-1, keepdim=True)\n",
        "        var = ((x - mu)**2).mean(-1, keepdim=True)\n",
        "        std = (var + self.eps).sqrt()\n",
        "        y = self.bias + self.weight*(x - mu)/std\n",
        "        return y\n",
        "\n",
        "if True:\n",
        "    LayerNorm = LayerNormalize\n",
        "else:\n",
        "    LayerNorm = nn.LayerNorm"
      ],
      "metadata": {
        "id": "MG_vqGG_j-0y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Kq-7UcjfdUEL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}