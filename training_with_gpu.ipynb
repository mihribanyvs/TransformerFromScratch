{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mihriban/gf_transformer/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "#import math\n",
    "import numpy as np\n",
    "#import random\n",
    "#import logging\n",
    "#import pandas as pd\n",
    "# Bring in PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "# Most of the examples have typing on the signatures for readability\n",
    "#from typing import Optional, Callable, List, Tuple\n",
    "#from Bio import SeqIO\n",
    "# For data loading\n",
    "#from torch.utils.data import Dataset, IterableDataset, TensorDataset, DataLoader\n",
    "#import json\n",
    "#import glob\n",
    "#import gzip\n",
    "#import bz2\n",
    "#import torch.nn.functional as F\n",
    "# For progress and timing\n",
    "#from tqdm import tqdm\n",
    "#import time\n",
    "#import shutil\n",
    "#from Bio.PDB import PDBList\n",
    "#from Bio.PDB.MMCIFParser import MMCIFParser\n",
    "import re\n",
    "#from Bio.PDB import PICIO, PDBIO\n",
    "#from Bio import PDB\n",
    "from transformers import BertModel, BertTokenizer, T5Tokenizer, T5EncoderModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from transformers import BertModel, BertTokenizer\\nimport re\\ntokenizer = BertTokenizer.from_pretrained(\"Rostlab/prot_bert\", do_lower_case=False )\\nseq = re.sub(r\"[UZOB]\", \"X\", seq_example)\\nencoded_input = tokenizer(seq, return_tensors=\\'pt\\')'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"from transformers import BertModel, BertTokenizer\n",
    "import re\n",
    "tokenizer = BertTokenizer.from_pretrained(\"Rostlab/prot_bert\", do_lower_case=False )\n",
    "seq = re.sub(r\"[UZOB]\", \"X\", seq_example)\n",
    "encoded_input = tokenizer(seq, return_tensors='pt')\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, embed_dim: int):\n",
    "        super(SelfAttention, self).__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.w_q = nn.Parameter(torch.randn(embed_dim, embed_dim))\n",
    "        self.w_k = nn.Parameter(torch.randn(embed_dim, embed_dim))\n",
    "        self.w_v = nn.Parameter(torch.randn(embed_dim, embed_dim))\n",
    "\n",
    "    def forward(self, embeddings_prot_bert: torch.Tensor) -> torch.Tensor:\n",
    "        Q = torch.matmul(embeddings_prot_bert, self.w_q)\n",
    "        K = torch.matmul(embeddings_prot_bert, self.w_k)\n",
    "        V = torch.matmul(embeddings_prot_bert, self.w_v)\n",
    "\n",
    "        scores = torch.matmul(Q, K.transpose(-1, -2)) / np.sqrt(K.size(-1))\n",
    "        attn = torch.softmax(scores, dim=-1)\n",
    "        attention_output = torch.matmul(attn, V)\n",
    "\n",
    "        return attention_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, embed_dim: int, feed_forward_dim1: int, feed_forward_dim2: int, output_dim: int = 2, dropout_rate: float = 0.1):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.self_attention = SelfAttention(embed_dim)\n",
    "        self.layer_norm1 = nn.LayerNorm(embed_dim)\n",
    "        self.layer_norm2 = nn.LayerNorm(output_dim)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.feed_forward = nn.Sequential(\n",
    "            nn.Linear(embed_dim, feed_forward_dim1),\n",
    "            nn.GELU(),\n",
    "            self.dropout,\n",
    "            nn.Linear(feed_forward_dim1, feed_forward_dim2),\n",
    "            nn.GELU(),\n",
    "            self.dropout,\n",
    "            nn.Linear(feed_forward_dim2, output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, embeddings: torch.Tensor) -> torch.Tensor:\n",
    "        attention_output = self.self_attention(embeddings)\n",
    "        normalized_attention_output = self.layer_norm1(attention_output)\n",
    "        ff_output = self.feed_forward(normalized_attention_output)\n",
    "        output = self.layer_norm2(ff_output)\n",
    "        return ff_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AngularLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AngularLoss, self).__init__()\n",
    "\n",
    "    def forward(self, predicted_angles, angles_tensor):\n",
    "        predicted_angles_phi, predicted_angles_psi = predicted_angles[:, 0], predicted_angles[:, 1]\n",
    "        angles_tensor_phi, angles_tensor_psi = angles_tensor[:, 0], angles_tensor[:, 1]\n",
    "\n",
    "        predicted_angles_phi = (predicted_angles_phi + torch.pi) % (2 * torch.pi) - torch.pi\n",
    "        angles_tensor_phi = (angles_tensor_phi + torch.pi) % (2 * torch.pi) - torch.pi\n",
    "        predicted_angles_psi = (predicted_angles_psi + torch.pi) % (2 * torch.pi) - torch.pi\n",
    "        angles_tensor_psi = (angles_tensor_psi + torch.pi) % (2 * torch.pi) - torch.pi\n",
    "\n",
    "        difference_phi = torch.abs(predicted_angles_phi - angles_tensor_phi)\n",
    "        loss_phi = torch.mean(torch.min(difference_phi, 2 * torch.pi - difference_phi))\n",
    "\n",
    "        difference_psi = torch.abs(predicted_angles_psi - angles_tensor_psi).to(device)\n",
    "        loss_psi = torch.mean(torch.min(difference_psi, 2 * torch.pi - difference_psi))\n",
    "        \n",
    "        loss = loss_phi + loss_psi\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLoss(nn.Module):\n",
    "    def __init__(self, predicted_angles, angles_tensor):\n",
    "        super(CustomLoss, self).__init__()\n",
    "        self.predicted_angles= predicted_angles\n",
    "        self.angles_tensor= angles_tensor\n",
    "    def forward(self):\n",
    "        d_list = []\n",
    "        for i in range(len(self.angles_tensor)):\n",
    "            x1, y1 = self.predicted_angles[0][i]\n",
    "            x2, y2 = self.angles_tensor[i]\n",
    "            ax_x = torch.min(torch.abs(x2 - x1), torch.abs(360 - torch.abs(x2 - x1)))\n",
    "            ax_y = torch.min(torch.abs(y2 - y1), torch.abs(360 - torch.abs(y2 - y1)))\n",
    "            d = torch.sqrt(ax_x**2 + ax_y**2)\n",
    "            d_list.append(d)\n",
    "        d_tensor = torch.stack(d_list)\n",
    "        return d_tensor.mean() \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerTrainer:\n",
    "    def __init__(self, model: nn.Module, criterion: nn.Module, num_epochs: int, sequence: torch.Tensor, angles: torch.Tensor):\n",
    "        self.model = model\n",
    "        self.criterion = criterion\n",
    "        self.num_epochs = num_epochs\n",
    "        self.sequence = sequence\n",
    "        self.angles_tensor = angles\n",
    "        self.optimizer = optim.AdamW(model.parameters(), lr=0.001)\n",
    "        #self.scheduler = optim.lr_scheduler.StepLR(self.optimizer, step_size=10, gamma=0.1)\n",
    "\n",
    "    def train(self):\n",
    "        loss_list = []\n",
    "        for epoch in range(self.num_epochs):\n",
    "            self.optimizer.zero_grad()\n",
    "            predictions = self.model.forward(self.sequence)[:, :len(self.angles_tensor)]\n",
    "            #loss = CustomLoss()\n",
    "            #loss.forward(torch.tensor(predictions, requires_grad=True), self.angles_tensor)\n",
    "            loss = self.criterion(predictions.squeeze(), self.angles_tensor)\n",
    "            loss.backward(retain_graph=True)\n",
    "            self.optimizer.step()\n",
    "            #self.scheduler.step()\n",
    "            loss_list.append(loss.item())\n",
    "            #print(f\"Epoch {epoch + 1}/{self.num_epochs}, Loss: {loss.item()}\")\n",
    "        return loss_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "source_dir = \"source\"\n",
    "#tokenizer = BertTokenizer.from_pretrained(\"Rostlab/prot_bert\", do_lower_case=False )\n",
    "#bert_model = BertModel.from_pretrained(\"Rostlab/prot_bert\")\n",
    "\n",
    "# Initialize and train transformer model\n",
    "feed_forward_dim1 = 512\n",
    "feed_forward_dim2 = 256\n",
    "feed_forward_dim3 = 128\n",
    "num_epochs = 100\n",
    "dropout_rate = 0.1\n",
    "transformer = TransformerModel(embed_dim=1024, feed_forward_dim1=feed_forward_dim1, feed_forward_dim2= feed_forward_dim2, dropout_rate = dropout_rate)\n",
    "criterion = AngularLoss()\n",
    "transformer = transformer.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = sorted(os.listdir(source_dir)) #[:50]\n",
    "\n",
    "seq_list = []\n",
    "angles_list = []\n",
    "for folder in folders:\n",
    "    folder_path = os.path.join(source_dir, folder)\n",
    "    if os.path.isdir(folder_path):\n",
    "        seq_path = os.path.join(folder_path ,f\"seq_{folder}.csv\" )\n",
    "        ang_path = os.path.join(folder_path, f\"angle_{folder}.csv\")\n",
    "        seq = torch.load(seq_path)\n",
    "        if len(seq.replace(' ','')) <= 128:\n",
    "            angle = torch.load(ang_path)\n",
    "            #angle_tensor = torch.from_numpy(angle.T)\n",
    "            seq_list.append(seq.replace(' ',''))\n",
    "            angles_list.append(angle.T)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding padding to the angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = max(len(x) for x in angles_list )\n",
    "padded_angles = []\n",
    "for angle in angles_list:\n",
    "    padding = np.zeros((max_length-len(angle),2))\n",
    "    padded_angles.append(np.vstack((angle,padding)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To add the padding Prot-T5 was used and batch encoding was done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading: Rostlab/prot_t5_xl_half_uniref50-enc\n"
     ]
    }
   ],
   "source": [
    "transformer_link = \"Rostlab/prot_t5_xl_half_uniref50-enc\"\n",
    "print(\"Loading: {}\".format(transformer_link))\n",
    "model = T5EncoderModel.from_pretrained(transformer_link)\n",
    "\n",
    "model = model.to(device)\n",
    "model = model.eval()\n",
    "tokenizer = T5Tokenizer.from_pretrained(transformer_link, do_lower_case=False, legacy=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Keyword arguments {'special_token': False} not recognized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3])\n"
     ]
    }
   ],
   "source": [
    "sequence_examples = [\"E M \"]\n",
    "\n",
    "# tokenize sequences and pad up to the longest sequence in the batch\n",
    "ids = tokenizer.batch_encode_plus(sequence_examples,special_token=False, padding=\"longest\")\n",
    "input_ids = torch.tensor(ids['input_ids']).to(device)\n",
    "attention_mask = torch.tensor(ids['attention_mask']).to(device)\n",
    "print(attention_mask.size())\n",
    "\n",
    "# generate embeddings\n",
    "with torch.no_grad():\n",
    "    embedding_repr = model(input_ids=input_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1622, -0.2762, -0.1633,  ..., -0.0368, -0.2990,  0.0872],\n",
       "        [ 0.4380, -0.1595, -0.3481,  ...,  0.0857, -0.1513, -0.1183],\n",
       "        [-0.1083, -0.0707,  0.0562,  ...,  0.0556,  0.0236,  0.0181]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_repr.last_hidden_state[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2630, -0.2531, -0.0511,  ..., -0.0465, -0.4211, -0.1257],\n",
       "        [-0.0713, -0.0862,  0.0057,  ...,  0.0311,  0.0302,  0.0646]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_repr.last_hidden_state[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([79, 129])\n"
     ]
    }
   ],
   "source": [
    "sequence_examples = [\" \".join(list(re.sub(r\"[UZOB]\", \"X\", sequence))) for sequence in seq_list]\n",
    "\n",
    "# tokenize sequences and pad up to the longest sequence in the batch\n",
    "ids = tokenizer.batch_encode_plus(sequence_examples, special_tokens=False,padding=\"longest\")\n",
    "input_ids = torch.tensor(ids['input_ids']).to(device)\n",
    "attention_mask = torch.tensor(ids['attention_mask']).to(device)\n",
    "print(attention_mask.size())\n",
    "\n",
    "# generate embeddings\n",
    "with torch.no_grad():\n",
    "    embedding_repr = model(input_ids=input_ids)\n",
    "\n",
    "#torch.save(embedding_repr.last_hidden_state,'embedding')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(len(sequence_examples[10].replace(' ','')))\n",
    "print(attention_mask[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoded input in the embedding space with dimensions (batch_size, max_length, 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([79, 128, 1024])\n"
     ]
    }
   ],
   "source": [
    "embedded_input = embedding_repr.last_hidden_state[:,:-1,:]\n",
    "print(embedded_input.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(transformer,'model_pretraining.pt')\n",
    "torch.save(transformer.state_dict(), 'pretraining_state_dict.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for index in range(embedded_input.size()[0]):\n",
    "    print(index)\n",
    "    N, D = embedded_input.size()[1], embedded_input.size()[2]\n",
    "    angles_tensor = torch.tensor(padded_angles[index]).to(device)\n",
    "    trainer = TransformerTrainer(transformer, criterion, num_epochs, embedded_input[index], angles_tensor)\n",
    "    trainer.train()\n",
    "    torch.save(transformer.state_dict(), 'model_postraining.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.6842,  0.4372,  0.6347,  ...,  0.9728,  2.7258,  1.0129],\n",
       "        [ 1.5015, -1.3181, -1.1218,  ..., -0.2082, -0.8369, -0.8994],\n",
       "        [-0.6838,  1.0184,  1.2882,  ...,  1.5031, -1.6067, -0.2977],\n",
       "        ...,\n",
       "        [-0.2741,  0.8392, -2.8594,  ..., -1.0226,  0.5374, -1.4510],\n",
       "        [-0.3024, -0.3968, -0.7321,  ...,  0.3048,  0.2136, -0.5446],\n",
       "        [ 0.6818, -1.2832, -0.8371,  ...,  0.4947,  0.5219,  0.3092]],\n",
       "       device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer.load_state_dict(torch.load('model_postraining.pt'))\n",
    "#transformer.eval()\n",
    "transformer.self_attention.w_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0187, -0.0189, -0.0550,  ...,  0.0329,  0.0374,  0.0220],\n",
       "        [ 0.0300,  0.0393,  0.0424,  ..., -0.0248, -0.0662, -0.0233],\n",
       "        [ 0.0221, -0.0276, -0.0060,  ...,  0.0411, -0.0376, -0.0208],\n",
       "        ...,\n",
       "        [ 0.0125, -0.0256, -0.0248,  ...,  0.0326,  0.0427, -0.0077],\n",
       "        [ 0.0340, -0.0050,  0.0277,  ...,  0.0365, -0.0277,  0.0311],\n",
       "        [-0.0572,  0.0129, -0.0105,  ...,  0.0029, -0.0041, -0.0759]],\n",
       "       device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer.feed_forward[0].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.7857,  0.6206,  0.6637,  ...,  0.9910,  2.9711,  1.0559],\n",
       "        [ 1.6767, -1.5417, -1.1654,  ..., -0.2459, -0.9541, -0.9731],\n",
       "        [-0.7866,  1.0688,  1.4431,  ...,  1.6864, -1.7418, -0.4119],\n",
       "        ...,\n",
       "        [-0.2409,  0.9181, -3.2631,  ..., -1.1879,  0.5847, -1.5172],\n",
       "        [-0.2963, -0.5263, -0.7923,  ...,  0.3881,  0.3060, -0.5665],\n",
       "        [ 0.6173, -1.5142, -0.8757,  ...,  0.6113,  0.5773,  0.2670]],\n",
       "       device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer.load_state_dict(torch.load('pretraining_state_dict.pt'))\n",
    "transformer.self_attention.w_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0275, -0.0310, -0.0194,  ...,  0.0067,  0.0306,  0.0037],\n",
       "        [-0.0020, -0.0056, -0.0154,  ..., -0.0240, -0.0273, -0.0221],\n",
       "        [ 0.0089, -0.0199,  0.0258,  ...,  0.0205, -0.0072, -0.0037],\n",
       "        ...,\n",
       "        [-0.0011, -0.0097, -0.0226,  ...,  0.0118, -0.0056, -0.0092],\n",
       "        [ 0.0300, -0.0111,  0.0061,  ...,  0.0139, -0.0180,  0.0113],\n",
       "        [-0.0158, -0.0188, -0.0037,  ...,  0.0021, -0.0111, -0.0222]],\n",
       "       device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer.feed_forward[0].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
